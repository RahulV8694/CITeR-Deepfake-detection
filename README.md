DeepFaceLab | Model: LIAE.f.128.80.48.16
This repository documents my custom-trained DeepFaceLab model using the LIAE architecture with high-resolution face extraction, optimized for production-ready deepfake pipelines. The model has been trained for 1,000,000 iterations on a GeForce RTX 2080 Ti, ensuring convergence and generalization across a wide variety of facial expressions and lighting conditions.


ğŸ“Œ Model Architecture Overview
Architecture: LIAE â€“ Light-Improved Autoencoder, suitable for efficient facial encoding and decoding.

Face Type: f â€“ Full face model (including forehead and chin), ideal for high fidelity swaps.

Resolution: 128x128 â€“ Balanced choice for performance and detail.

Iteration Count: 1,000,000 â€“ Ensures convergence and stability during inference.

ğŸ§  Technical Configuration
Parameter	Value	Description
archi	liae	LIAE architecture (multi-decoder encoder-decoder).
face_type	f	Full-face training to maximize realism.
ae_dims	128	Autoencoder latent space dimensionality.
e_dims	80	Encoder capacity â€“ controls feature richness.
d_dims	48	Decoder capacity for final face generation.
d_mask_dims	16	Mask decoder dimensions â€“ enhances blending.
masked_training	True	Applies binary face masks for training stabilization.
learn_mask	True	Learns facial boundaries explicitly.
eyes_prio	True	Prioritizes eye-region detail for realism.
gan_power	0.0	GAN training disabled (focuses on reconstruction).
random_warp	True	Data augmentation using warps.
random_flip	True	Enables horizontal flips for generalization.
batch_size	8	Training batch size.
pretrain	True	Pretrained base used for warm start.
write_preview_history	False	Live previews only.
clipgrad	False	Gradient clipping disabled.
target_iter	1,000,000	Final iteration target.

âš™ï¸ Training Environment
GPU: NVIDIA GeForce RTX 2080 Ti

VRAM: 11GB

OS: Windows 10 (DeepFaceLab GPU build)

Framework: DeepFaceLab (Latest fork by iperov)

CUDA/CuDNN: CUDA 11.x, cuDNN 8.x

ğŸ§ª Use Case
This model is optimized for:

High-fidelity face swaps

Biometric research and spoof testing

Digital doubles for VFX

Academic investigation of generative models

ğŸ“¦ Files & Structure
plaintext
Copy
Edit
workspace/
â”œâ”€â”€ aligned/           # Aligned source face images
â”œâ”€â”€ model/             # Trained model weights
â”‚   â”œâ”€â”€ d_encoder.h5
â”‚   â”œâ”€â”€ d_decoder.h5
â”‚   â”œâ”€â”€ inter_AB.h5
â”‚   â”œâ”€â”€ inter_BA.h5
â”‚   â””â”€â”€ ...
â”œâ”€â”€ data_dst/          # Destination face images
â”œâ”€â”€ result/            # Inference output
ğŸ“Š Training Performance
Metric	Value
Iterations	1,000,000
Final Loss	~0.020â€“0.035
Preview Quality	Excellent
Swap Consistency	High

ğŸ“ Future Work
Fine-tune with GAN enabled (gan_power > 0) for hyperrealism

Train with ct_mode: 'hist_match' for lighting consistency

Benchmark LIAE vs SAEHD vs DFL-H128 on perceptual realism metrics

ğŸ§‘â€ğŸ’» Author
Rahul Vijaykumar
Machine Learning Engineer | Biometric Researcher
